[
 {
  "content": "Subscribe to the O'Reilly Radar Podcastto track the technologies and people that will shape our world in the years to come.In this week's episode, O'Reilly'sMac Slocumchats withKristian Hammond,Narrative Science'schief scientist. Hammond talks aboutNatural Language Generation, Narrative Science's shift into the world of business data, and evolving beyond the dashboard.Here are a few highlights:We're not telling people what the data are; we're telling people what has happened in the world through a view of that data. I don't care what the numbers are; I care about who are my best salespeople, where are my logistical bottlenecks.Quillcan do that analysis and then tell you &mdash; not make you fight with it, but just tell you &mdash; and tell you in a way that is understandable and includes an explanation about why it believes this to be the case. Our focus is entirely, a little bit in media, but almost entirely in proprietary business data, and in particular we really focus on financial services right now.You can't make good on that promise [of what big data was supposed to do] unless you communicate it in the right way. People don't understand charts; they don't understand graphs; they don't understand lines on a page. They just don't. We can't be angry at them for being human. Instead we should actually have the machine do what it needs to do in order to fill that gap between what it knows and what people need to know.moreThe point of the technology is to humanize the machine so we don't have to mechanize people. I always think it's a sad, sad state of the world where technologists keep demanding that everyone become data literate. What they mean is that everyone needs to have the analytical skills needed to look at a data set and figure out what's going on. I always see that as technologists saying, \"We failed. We could not figure out how to explain to you what's going on, so you have to have our skills.\" While I think it's a noble notion that everybody has these skills, it's not going to happen. At the end of the day, it's not democratizing data to say we're going to do that. It's meritocratizing data. It's saying, \"The only people who are allowed to understand what's happening in the world, based upon this data, are the people who have these high-end skills.\" It's incumbent upon us as technologists to move that data into information that is absolutely accessible to regular people. If we don't do it, we have failed.I think over the next two years, we're actually going to see a shift in the business attitude toward artificial intelligence. Right now, businesses are really struggling with, \"What's going to be my AI or cognitive computing strategy?\" That's going to shift into, \"I have particular problems, are there particular AI systems that can solve these problems?\" What we're going to get is a much more rational approach to the introduction of AI into the business world. It's not, \"We need machine learning,\" it's, \"We actually need to understand Churn.\" It's not that we need predictive analytics, it's that we actually need to know when our supply chains are going to break down.Subscribe to the O'Reilly Radar PodcastStitcher,TuneIn,iTunes,SoundCloud,RSSImage byRobert Couse-Baker on Flickr, used under aCreative Commons license.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/We_WLYItj7c/kristian-hammond-on-truly-democratizing-data-and-the-value-of-ai-in-the-enterprise.html", 
  "title": "Kristian Hammond on truly democratizing data and the value of AI in the enterprise"
 }, 
 {
  "content": "Subscribe to the O'Reilly Design Podcast, our podcast exploring how experience design &mdash; and experience designers &mdash; are shaping business, the Internet of Things, and other domains.In this week's Design Podcast episode, I sit down withVanessa Cho, head of UX  and research for the software and services group at GoPro. Cho, along with her hardware colleagueWesley Yun, will be speaking atO'Reilly's inaugural Design Conferencein January. We talk about designing for hardware and software, building design teams, and what she looks for in new recruits.Here are a few highlights from our conversation:I started at GoPro 18 months ago. I was one of the first designers, and in that time, we've grown to 18 designers &mdash; 18 designers in 18 months. We've spent a lot time recruiting and honing down on what is really important to us.At GoPro, we're building a hybrid model that allows us to harness specialized skills while delivering speed and scale. What we have is embedded UX generalists for each of the product teams who can champion the customer experience and help define the product and the value of it. Simultaneously, we have a group of shared services, which is filled with specialists, researchers, visual designers, content strategists, and then also me as a manager, that work to help support the UX generalists that are embedded in the team. They're ensuring that the team not only is working well together but it's delivering consistent, on-brand quality work. This model \u2026 requires a lot of collaboration and communication between the individuals. \u2026 It also helps significantly that I have a very tenured, and mature, and collaborative team that always helps, not only on the software side, but also on the hardware side. We have excellent partnership there.moreYou know, hardware and software are very much like apples and oranges. Your job as a designer is to invent a peeler that works for both.Hardware and software are motivated for different outcomes. Specifically, I think hardware has to be solution driven. They only have one chance to make that one product perfect. They can't release the product and then quickly update it and be like, 'Sorry. That wasn't really good. Here, let's send another update to the app store.' Once it's out there, it really is out there. It's final. On the other hand, software is totally different in the sense where it's not about a final product at a specific point in time; it's much more about the process, about evolving the product itself. It's about hypothesizing, concepting, learning, iterating, and changing. I definitely think that a hardware designer does that, too. They must. They absolutely have to, but they still have to design for a finished product. A final, final product. The software designer, I feel, usually has the attitude that ... the product is never finished. You can always learn, and iterate, and go through betas, alphas and betas. It's like a public beta.I think all you really need is to find great hardware peers or software peers, regardless of where you are, who share that understanding of design thinking about how you actually create solutions or concepts and test those particular things out. Once you have that shared thinking, you can make that ecosystem really sing.Subscribe to the O'Reilly Design PodcastStitcher,TuneIn,iTunes,SoundCloud,RSSImage byKyle Pearce on Flickr.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/hbP636Lsh8g/vanessa-cho-on-gopros-design-approach.html", 
  "title": "Vanessa Cho on GoPro\u2019s design approach"
 }, 
 {
  "content": "uitable-- cute library for tabular data in console golang programs.Did Carnegie Mellon Attack Tor for the FBI?(Bruce Schneier) --The behavior of the researchers is reprehensible, but the real issue is that CERT Coordination Center (CERT/CC) has lost its credibility as an honest broker. The researchers discovered this vulnerability and submitted it to CERT. Neither the researchers nor CERT disclosed this vulnerability to the Tor Project. Instead, the researchers apparently used this vulnerability to deanonymize a large number of hidden service visitors and provide the information to the FBI. Does anyone still trust CERT to behave in the Internet's best interests?Analogous to the CIA organizing a fake vaccination drive to get close to Osama. \"Intelligence\" agencies.Google Open-Sourcing TensorFlow Shows AI's Future is Data not Code(Wired) -- something we've been sayingfor a long time.Challenges of Working Remote(Moishe Lettvin) --the things that make working remote hard aren't, primarily, logistical; they're emotional.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/Gb-1dDh2PUY/four-short-links-24-november-2015.html", 
  "title": "Four short links: 24 November 2015"
 }, 
 {
  "content": "SVG rendering uses a painter's model to describe how graphics are rendered to the screen.  Like layers of paint on a wall, content on top obscures content below.  The SVG specifications define which content gets painted over which other content.  The different parts of each shape &mdash; the stroke, fill, and markers &mdash; each create layers of paint.  Those shapes are then layered one on top of the other, in the order they are defined in the document.Two new properties introduced by the SVG 2 specification,z-indexandpaint-order, allow you to change up the rendering rules.Most web designers will be familiar withz-index, which has been supported in CSS layout for years.  Unfortunately, it isnotyet supported in any major web browser for SVG content.  At present, the only solution is to arrange your markup (or the DOM created by scripts) so that elements are listed in the order you want them to be painted.In contrast, thepaint-orderproperty has already been implemented in a number of web browsers.  If you're willing to make adjustments in your design according to browser support level, you can use the fine-tuned control in the latest browsers and replace it with a simpler effect in others.  If you need the same appearance inallbrowsers, however, you can create something thatlookslike paint order control with SVG 1.1 code.  This post describes whypaint-orderis useful, how to use it in the latest browsers, and how to fake it in the others.moreUnderstanding the SVG paint propertiesThe shape elements in you SVG code define precise geometric curves using resolution-independent mathematical relationships.  An SVG&lt;line&gt;is just the idea of a line, connecting two infinitesimal points; it has no thickness of its own.  Text in SVG is also defined as geometric outlines, based on the vector curves in the font files.When you include a shape or text element in an SVG without any style information, it is displayed as a solid black region exactly matching the dimensions you specify.  This is the defaultfillvalue: solid black.Thefillproperty tells the SVG-rendering software what to do with that geometric shape.  For every pixel on the screen &mdash; or ink spot on the paper &mdash; the software determines if that point is inside or outside of the shape.  If it is inside, the software turns to thefillvalue to find out what to do next.In the simple case (like the default black), the fill value is a color and all the points inside the shape get replaced by that color.  In other cases, the fill value is an instruction to look up more complicated painting code.  Where to look it up is indicated by a URL referencing theidof an SVG element representing the instructions (aka, apaint server, such as a gradient or pattern).In addition to &mdash; or instead of &mdash; a fill, you can paint a shape bystrokingit. In computer graphics, stroking a shape means drawing a line along its edge.  Different programs have different interpretations of what that can mean.In SVG (currently, anyway), stroking is implemented by generating a secondary shape extending outwards and inwards from the edges of the main shape.  Thestrokeproperty is by defaultnone, but it can be set to a color value or a paint server reference to create a visible stroke.  The thickness of the stroke (set by thestroke-widthproperty) is centered over the edge of the shape, half overlapping the fill region and half outside.  Other stroke-related properties control the details of the generated shape, such as how it wraps around corners, or break the shape into a dashed line.The stroke region is then painted using the same approach as for filling the main shape: the software scans across, and determines whether a point is inside or outside the stroke.  If the point is inside, the software uses the painting instructions from thestrokeproperty to assign a color.The order of operationsWhen a shape hasbothfillandstrokepaint, some pixels are included in both the fill area and the stroke region, and therefore have two different colors specified.  As with all of SVG, the painter's model applies: if both colors are opaque, the color of the layer on top replaces the color of the layer below.But which layer is \"on top\"?By default, the stroke is painted on top of the fill.  This means that you can always see the full stroke width.  It also means that if the stroke is partially-transparent, it will appear two-toned.  The fill paint color will be visible under the inner half of the stroke region but not under the outer half.Tip:Stroke markers &mdash; symbols that display on the corners of custom shapes &mdash; are painted after the fill and stroke, in order from start to end of the path.In SVG 1.1, the only way to draw a stroke underneath the fill is to separate it into two shapes: one with stroke only, and then the same shape duplicated in the same position (with a&lt;use&gt;element), filled but not stroked:&lt;g stroke=\"blue\" fill=\"red\"&gt;\n    &lt;g fill=\"none\"&gt;\n        &lt;path id=\"shape\" d=\"...\" /&gt;\n    &lt;/g&gt;\n    &lt;use xlink:href=\"#shape\" stroke=\"none\" /&gt;\n&lt;/g&gt;The above snippet makes extensive use of inherited styles.  The&lt;path&gt;itself does not have any fill or stroke values directly set; it inherits from its surrounding.  The overall stroke and fill values are set on the containing&lt;g&gt;; one or the other is then cancelled out on the nested group and the&lt;use&gt;element.SVG 2 introduces thepaint-orderproperty to make this effect much easier to achieve.  Its value is a list of whitespace-separated keywords (fill,stroke, andmarkers) that indicate the order in which the various parts of the shape should be painted.  So the same effect could be created with a single element:&lt;path id=\"shape\" d=\"...\" stroke=\"blue\" fill=\"red\" \n      paint-order=\"stroke fill\" /&gt;Any paint layers you don't specify in thepaint-orderproperty will be painted later (markers, in this case), in the same order they normally would be.  This means that to swap fill and stroke, you only need to specify the stroke:&lt;path id=\"shape\" d=\"...\" stroke=\"blue\" fill=\"red\" \n      paint-order=\"stroke\" /&gt;The stroke will be painted first, then fill, and finally any markers.  The entire fill region will always be visible, even where it overlaps the stroke.The default value ofpaint-order(equivalent tofill stroke markers) can be explicitly set with thenormalkeyword.WARNING:At the time of writing,paint-orderis supported in the latest Firefox (since version 31), Blink (since Chromium version 35), and WebKit (since March 2014) browsers.  Internet Explorer and Edge, as well as older versions of the other browsers, use the default paint order.The ability to control painting order is especially important with text.  Text in SVG can be stroked just like shapes can, to create an outlined effect.  However, all but the thinnest strokes tend to obscure the details of the letters.By painting the fill region overtop of the stroke &mdash; in a contrasting color &mdash; you can reinforce the shape of the letters and restore legibility.paint-order-exampleusespaint-orderand a thick stroke to create a crisp outline around heading text.paint-order-okay-figureshows the result in a supporting browser.paint-order-exampleStroking without obscuring the finer details of text:&lt;svg xmlns=\"http://www.w3.org/2000/svg\"\n     viewBox=\"0 0 400 80\" width=\"4in\" height=\"0.8in\"\n     xml:lang=\"en\"&gt;\n    &lt;title&gt;Outlined text, using paint-order&lt;/title&gt;\n    &lt;rect fill=\"navy\" height=\"100%\" width=\"100%\" /&gt;\n    &lt;text x=\"50%\" y=\"70\" \n          text-anchor=\"middle\"\n          font-size=\"80\" \n          font-family=\"sans-serif\"\n          fill=\"mediumBlue\" \n          stroke=\"gold\"\n          stroke-width=\"7\"\n          paint-order=\"stroke\"\n          &gt;Outlined&lt;/text&gt;\n&lt;/svg&gt;paint-order-okay-figureOutlined text with strokes painted behind the fill:Falling back gracefullyIf you relied solely onpaint-orderto achieve this effect, your text would be a blocky mess on unsupporting browsers, as shown inpaint-order-no-support-figure.  Some fallback strategies are in order.paint-order-no-support-figureOutlined text with strokes painted using the default order:One solution is to use the CSS@supportsconditional rule to only apply the outline effect ifpaint-orderis supported.  In other cases, use a different styling that provides legible text &mdash; if not the desired effect.paint-order-supports-exampleprovides a modified version of the code frompaint-order-example; the styles have been moved from presentation attributes to a&lt;style&gt;block so that conditional CSS can be applied.  The basic styles include a much narrower stroke when painting order cannot be controlled; the@supportsblock replaces this with the thick stroke andpaint-orderoption.The result looks the same aspaint-order-okay-figurein browsers that supportpaint-order(all of which currently also support the@supportsrule).paint-order-supports-figureshows how the revised code looks in other browsers.paint-order-supports-exampleTesting support before using paint-order:&lt;svg xmlns=\"http://www.w3.org/2000/svg\"\n     viewBox=\"0 0 400 80\" width=\"4in\" height=\"0.8in\"\n     xml:lang=\"en\"&gt;\n    &lt;title&gt;Using @supports to adjust paint-order effects&lt;/title&gt;\n    &lt;style type=\"text/css\"&gt;\n        .outlined {\n          text-anchor: middle;\n          font-size: 80px; \n          font-family: sans-serif;\n          fill: mediumBlue; \n          stroke: gold;\n\n          /* fallback */\n          stroke-width: 3;\n        }\n\n        @supports (paint-order: stroke) {\n            .outlined {\n              stroke-width: 7;\n              paint-order: stroke;\n            }\n        }\n    &lt;/style&gt;\n    &lt;rect fill=\"navy\" height=\"100%\" width=\"100%\" /&gt;\n    &lt;text x=\"50%\" y=\"70\" class=\"outlined\"\n          &gt;Outlined&lt;/text&gt;\n&lt;/svg&gt;paint-order-supports-figureText with a narrower outline when paint-order is not supported:Tip:Thestroke-widthhas been cut by more than half betweenpaint-order-okay-figureandpaint-order-supports-figure. However, the stroke only appears slightly narrower, because the inside half of the stroke is now visible on top of the fill.If changing the appearance with@supportsis not acceptable to you, the only alternative is to duplicate the elements to create one for stroke and one for fill.  Depending on the way you are using your SVG, and how much control you have over its styling, you may be able to use a script to perform the conversion for you when necessary.  Becausepaint-orderis a new style property, browsers that do not support it will not include it within thestyleproperty of each element.  You can therefore detect these browsers and generate the extra&lt;use&gt;elements as required.paint-order-script-exampleprovides a sample script which identifies elements by classname and performs the manipulations if required.  The result (in a browser that does not supportpaint-order) is shown inpaint-order-script-figure. Although it appears identical topaint-order-okay-figure, the underlying DOM structure is much more complex.paint-order-script-exampleSimulating paint-order with Multiple Elements:&lt;svg xmlns=\"http://www.w3.org/2000/svg\"\n     xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     viewBox=\"0 0 400 80\" width=\"4in\" height=\"0.8in\"\n     xml:lang=\"en\"&gt;\n    &lt;title&gt;Faking paint-order with JavaScript&lt;/title&gt;\n    &lt;style type=\"text/css\"&gt;\n        .outlined {\n          text-anchor: middle;\n          font-size: 80px; \n          font-family: sans-serif;\n          fill: mediumBlue; \n          stroke: gold;\n          stroke-width: 7;\n          paint-order: stroke;\n        }\n    &lt;/style&gt;\n    &lt;rect fill=\"navy\" height=\"100%\" width=\"100%\" /&gt;\n    &lt;text x=\"50%\" y=\"70\" class=\"outlined\"\n          &gt;Outlined&lt;/text&gt;\n    &lt;script&gt;&lt;![CDATA[\n(function(){\n    var NS = {svg: \"http://www.w3.org/2000/svg\",\n              xlink: \"http://www.w3.org/1999/xlink\"\n             };\n    var index = 10000;\n\n    var t = document.getElementsByClassName(\"outlined\");   //&lt;1&gt;\n    if ( t &amp;&amp; \n        (t[0].style[\"paint-order\"] === undefined )){       //&lt;2&gt;\n        Array.prototype.forEach.call(t, fakeOutline);      //&lt;3&gt;\n    }\n\n    function fakeOutline(el){\n        el.id = el.id || \"el-\" + index++;                  //&lt;4&gt;\n\n        var g1 = document.createElementNS(NS.svg, \"g\");    //&lt;5&gt;\n        g1.setAttribute(\"class\", el.getAttribute(\"class\") );\n        el.removeAttribute(\"class\");\n        el.parentNode.insertBefore(g1, el);\n\n        var g2 = document.createElementNS(NS.svg, \"g\");    //&lt;6&gt;\n        g2.style[\"fill\"] = \"none\";\n        g2.insertBefore(el, null);\n        g1.insertBefore(g2, null);\n\n        var u = document.createElementNS(NS.svg, \"use\");   //&lt;7&gt;\n        u.setAttributeNS(NS.xlink, \"href\", \"#\" + el.id);\n        u.style[\"stroke\"] = \"none\";\n        g1.insertBefore(u, null);\n    }\n})();\n]]&gt; &lt;/script&gt;\n&lt;/svg&gt;<1>The elements to modify are identified by a specific class name,\"outlined\", for easy access in the script.<2>Thestyleproperty ofanyelement (here, the first element selected) can be examined to determine if it supports thepaint-orderproperty.  A strict equality test (===) is used to distinguish an empty value (no inline style was set on the element) from an undefined value (the property name is not recognized).<3>If the fallback is required, thefakeOutline()method is called for each element that had the class name.  TheforEach()array method is used to call the function as many times as needed.  However, since the list returned bygetElementsByClassName()is not a true JavaScriptArrayobject, you cannot uset.forEach(fakeOutline).  Instead, theforEach()function is extracted from theArrayprototype and then invoked using its owncall()method.<4>ThefakeOutline()function will duplicate the outlined element with a&lt;use&gt;element, so it will need a valididvalue; if it doesn't already have one, an arbitrary value is added with a unique index.<5>The element is replaced by a group that is transferred all of its classes.  This of course requires that allfillandstrokestyles are assigned via class, and not by tag name or via presentation attributes.  TheinsertBefore()method is used to ensure that the new group will have the same position in the DOM tree as the element it is replacing.<6>A nested group will hold the original element, but will prevent it from inheriting thefillstyle.<7>Finally, a&lt;use&gt;element duplicates the element, but cancels out thestrokestyle so that it only inheritsfillstyles.  It is inserted into the main group as the last child (\"before\" nothing), so that it will be drawn on top of the version with no fill.paint-order-script-figureText duplicated to mimic a stroke-first paint order:As you can tell, the script is rather convoluted for such a simple effect.  A more generic fallback script &mdash; a complete polyfill for the property &mdash; would be even more complex, as you would need to account for all the different ways in which a style property can be applied to an element.  Effectively, you need to recreate the work of the CSS parser, identifying all the style rules it discarded as invalid.In most cases, if the final appearance is essential in all browsers, it is easier to create the layered stroke and fill copies of the object within your markup, directly creating the structure that would be generated by the script:&lt;g class=\"outlined\"&gt;\n    &lt;g style=\"fill: none;\"&gt;\n        &lt;text id=\"el-10000\" x=\"50%\" y=\"70\"&gt;Outlined&lt;/text&gt;\n    &lt;/g&gt;\n    &lt;use style=\"stroke: none;\" xlink:href=\"#el-10000\" /&gt;\n&lt;/g&gt;Public domain spline image viaWikipedia.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/6_PuLcbhYJw/elegant-outlines-with-svg-paint-order.html", 
  "title": "Elegant Outlines with SVG paint-order"
 }, 
 {
  "content": "Subscribe to the O'Reilly Radar Podcastto track the technologies and people that will shape our world in the years to come.In this week's episode of the Radar Podcast, O'Reilly'sMary Treselerchats withMike Kuniavsky, a principal scientist in the Innovation Services Group at PARC. Kuniavsky talks about designing for the Internet of Things ecosystem and why the most interesting thing about the IoT isn't the \"things\" but the sensors. He also talks about his deep-seated love for appliances and furniture, and how intelligence will affect those industries.Here are some highlights from their conversation:Wearables as a class is really weird. It describeswherethe thing is, notwhatit is. It's like referring to kitchenables. 'Oh, I'm making a kitchenable.' What does that mean? What does it do for you?There's this slippery slope between service design and UX design. I think UX design is more digital and service design allows itself to include things like a poster that's on a wall in a lobby, or a little card that gets mailed to people, or a human being that they can talk to. ... Service design takes a slightly broader view, whereas UX design is &mdash; and I think usefully &mdash; still focused largely on the digital aspect of it.moreI have a deep, long-seated love for appliances and for furniture because they are the tools of our everyday lives, and if anything becomes the content of this new Internet of Things thing first, it's them. What's interesting to me is that they have an already existing set of affordances, which means people know what to do with them and how to do it. They have a set of expectations, and how this set of things can now utilize this amazing set of sensing and actuation and meaning-making and statistical analysis technologies that are available up in the cloud, to do the things that they have always done, but do it better. I'm really interested in how intelligence affects the appliance industry.There are ways to spin the IoT as an Orwellian cyberpunk anti-future, things that spy on you from every corner. They will do that, but I'm not that interested in that aspect of it. I think, actually, that humans are pretty good at negotiating their technologies, even though it sometimes takes a while.The thing that is happening right now is that by connecting all of these different sensing devices, you turn that sensor input from this very simple gas gauge-like thing that might be useful to somebody in one situation, to a sequence of knowledge that can be modeled and can be much more broadly useful, especially when you have many, many different sources of information that are coming together. That, to me, is a tectonic shift because now you can essentially reason on a giant quantity of information, but the end points that are collecting this information or acting on it can be incredibly small and thin. You get the full power of these enormous artificial intelligence systems, machine learning systems, but without any of the computational overhead or cost, locally. That is really powerful. Every single little thing becomes as powerful as the most powerful computer on earth, and can then anticipate, compensate, and work together with other things in ways that were inconceivable before this shift.What I'm interested in, broadly speaking, is predictive analytics &mdash; I should say, machine learning, statistical modeling, but specifically inpredictivestatistical modeling, predictive machine learning. I think, really, that is the new super power.Subscribe to the O'Reilly Radar PodcastStitcher,TuneIn,iTunes,SoundCloud,RSSImage by Daniel Mayer on Wikimedia Commons.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/5Bv9xCHtJ6k/mike-kuniavsky-on-the-tectonic-shift-of-the-iot.html", 
  "title": "Mike Kuniavsky on the tectonic shift of the IoT"
 }, 
 {
  "content": "Subscribe to the O'Reilly Data Show Podcastto explore the opportunities and techniques driving big data and data science.Given the quick pace of innovation in the data ecosystem, we like to take a step back from the details of individual components, architecture, and applications, in order to take a wider view of the landscape of big data. This allows us to evaluate the progress of technology and infrastructure along the way, shifting our attention from the details of individual components like Spark and Kafka, to larger trends.Some of the larger trends we've been exploring include the capabilities of distributedmachine learningand the tradeoffs and design decisions involved in cloud architecture and stream processing.In this episode of the O'Reilly Data Show, I sat down withJai Ranganathan, senior director of product management at Cloudera. We talked about the trends in the Hadoop ecosystem, cloud computing, the recentsurge in interest in all things real time, and hardware trends:Large-scale machine learningThis sounds a bit like this should already exist in really good form right now, but one of the things that I'm really interested in is expanding the set of capabilities for distributed machine learning. While there are systems out there today that do do this, I think relative to what you can experience from a singular environment learning scikit-learn or R, the set of things you can do in a distributed fashion is limited. ... \u00a0It's not easy to distribute various algorithms and model-building techniques. I think there is still a lot of work for us to do to improve that experience. ... And I do want to have good open source options like MLlib. MLlib may be the right answer. I would be perfectly happy if that's the final answer, but we do need systems just to provide the kind of depth that you typically are used to in the singular environment. That's just a matter of time and investment because these are non-trivial problems, but they are things that people are working on.moreArchitecting data applications in the cloudThere are some fundamental design principles behind the original HDFS implementation, which don't actually work in the cloud. For example, this notion that data locality is fundamental to this system design; it starts changing in the cloud when you're looking at these large cloud providers &mdash; they are doing all these software-defined networking tricks and they can do bisectional bandwidth, like 40 gigs per second, across their data center ... suddenly, you're talking about moving hundreds of terabytes of data back and forth from a storage to a compute layer without any huge performance penalties. Suddenly, their performance is disadvantageous to this, but it's not as bad as you think. Some of the core design principles in Hadoop have to change when you think about this kind of new data center design. ... The cloud part is really interesting, but really what to me is interesting is there's a fundamental shift in the way data centers are being designed, which we have to make sure that Hadoop stays designed to capitalize on....A lot of the work we do on the cloud is to optimize working with these object stores effectively. Obviously, you still need some local storage for things like spill, but that's not really the same as a distributed file system. Then, it's really a question of getting all the frameworks to run really effectively against an object store.Paying attention to hardware trendsWhen I joined Cloudera, a customer who was going crazy and buying the most expensive hardware was buying 64 gigabytes of RAM. On that 64 gigabytes of RAM, they also had 12 disk spindles with two terabytes each and 24 terabytes of disk. At this point, today, many of my customers buy 246 gigabytes of RAM or even potentially 384 gigabytes to 512 gigabytes of RAM. The amount of disk is still exactly the same. Because disks don't spin faster and you still want a certain level of throughput, you're still looking at 24 terabytes of disk in your machine. Already in just two years, we have seen it go from 64 to 512, potentially. I don't think this trend is going to stop, and we are suddenly going to be looking at, within three years, one-terabyte RAM machines....What we're finding is that in a lot of the things we do at Cloudera, like Kudu or Impala, fundamentally, we really care about wringing performance out of the CPU. A lot of this will be like, 'can I do vectorize operations?' and 'can I make sure to take advantage of my L2 cache mode effectively?' because that allows my CPU to spend more efficiently. It really changes the bottleneck from the I/O subsystem to the CPU subsystem, and everything you can do to eke out performance there really matters. ... Project Tungsten is basically in the Spark community to do more CPU-efficient things, whether that's vectorizing stuff, whether that's actually effectively moving away from managed memory to managing by buffers, so you can actually have much more efficient handling of memory, so you can get better CPU efficiency as well.Subscribe to the O'Reilly Data Show PodcastStitcher,TuneIn,iTunes,SoundCloud,RSSRelated resources:Jai Ranganthan will be speaking at Strata + Hadoop World Singapore:Hadoop in the cloud &mdash; an architectural how-toWhy the data center needs an operating systemby Benjamin Hindman, creator of Apache MesosShowcasing the real-time processing revival: Tools and learning resources for building intelligent, real-time products(sessions at Strata + Hadoop World NYC)Apache Spark: Powering applications on-premise and in the cloud, a Data Show episode featuring Spark's release manager, Patrick Wendell.Imagevia Henry Hopkins on Wikimedia Commons.", 
  "link": "http://feedproxy.google.com/~r/oreilly/radar/atom/~3/ZQdoRwBeVog/jai-ranganathan-on-architecting-big-data-applications-in-the-cloud.html", 
  "title": "Jai Ranganathan on architecting big data applications in the cloud"
 }
]